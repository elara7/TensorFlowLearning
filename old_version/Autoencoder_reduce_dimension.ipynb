{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kenn/anaconda3/envs/tf_base/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-bb757b2ec8b9>:5: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/kenn/anaconda3/envs/tf_base/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/kenn/anaconda3/envs/tf_base/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/kenn/anaconda3/envs/tf_base/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/kenn/anaconda3/envs/tf_base/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\",one_hot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "training_epochs = 50\n",
    "batch_size = 256\n",
    "display_step = 1\n",
    "examples_to_show = 10\n",
    "\n",
    "n_input = 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32,[None,n_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden_1 = 256\n",
    "n_hidden_2 = 64\n",
    "n_hidden_3 = 10\n",
    "n_hidden_4 = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    \"encoder_w1\":tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    \"encoder_w2\":tf.Variable(tf.random_normal([n_hidden_1,n_hidden_2])),\n",
    "    \"encoder_w3\":tf.Variable(tf.random_normal([n_hidden_2, n_hidden_3])),\n",
    "    \"encoder_w4\":tf.Variable(tf.random_normal([n_hidden_3,n_hidden_4])),\n",
    "    \n",
    "    \"decoder_w1\":tf.Variable(tf.random_normal([n_hidden_4,n_hidden_3])),\n",
    "    \"decoder_w2\":tf.Variable(tf.random_normal([n_hidden_3,n_hidden_2])),\n",
    "    \"decoder_w3\":tf.Variable(tf.random_normal([n_hidden_2,n_hidden_1])),\n",
    "    \"decoder_w4\":tf.Variable(tf.random_normal([n_hidden_1,n_input]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    \"encoder_b1\":tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    \"encoder_b2\":tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    \"encoder_b3\":tf.Variable(tf.random_normal([n_hidden_3])),\n",
    "    \"encoder_b4\":tf.Variable(tf.random_normal([n_hidden_4])),\n",
    "    \n",
    "    \"decoder_b1\":tf.Variable(tf.random_normal([n_hidden_3])),\n",
    "    \"decoder_b2\":tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    \"decoder_b3\":tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    \"decoder_b4\":tf.Variable(tf.random_normal([n_input]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(x):\n",
    "    layer_1 = tf.nn.sigmoid(tf.matmul(x, weights[\"encoder_w1\"])+ biases[\"encoder_b1\"])\n",
    "    layer_2 = tf.nn.sigmoid(tf.matmul(layer_1, weights[\"encoder_w2\"])+ biases[\"encoder_b2\"])\n",
    "    layer_3 = tf.nn.sigmoid(tf.matmul(layer_2, weights[\"encoder_w3\"])+ biases[\"encoder_b3\"])\n",
    "    layer_4 = tf.matmul(layer_3, weights[\"encoder_w4\"])+ biases[\"encoder_b4\"]\n",
    "    return layer_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(x):\n",
    "    layer_1 = tf.nn.sigmoid(tf.matmul(x, weights[\"decoder_w1\"])+ biases[\"decoder_b1\"])\n",
    "    layer_2 = tf.nn.sigmoid(tf.matmul(layer_1, weights[\"decoder_w2\"])+ biases[\"decoder_b2\"])\n",
    "    layer_3 = tf.nn.sigmoid(tf.matmul(layer_2, weights[\"decoder_w3\"])+ biases[\"decoder_b3\"])\n",
    "    layer_4 = tf.nn.sigmoid(tf.matmul(layer_3, weights[\"decoder_w4\"])+ biases[\"decoder_b4\"])\n",
    "    return layer_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_op = encoder(X)\n",
    "decoder_op = decoder(encoder_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = decoder_op\n",
    "y_true = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "Epoch: 0001 cost =  0.148976177\n",
      "Epoch: 0002 cost =  0.131343246\n",
      "Epoch: 0003 cost =  0.106404044\n",
      "Epoch: 0004 cost =  0.094118491\n",
      "Epoch: 0005 cost =  0.090083279\n",
      "Epoch: 0006 cost =  0.086008519\n",
      "Epoch: 0007 cost =  0.083323792\n",
      "Epoch: 0008 cost =  0.083460711\n",
      "Epoch: 0009 cost =  0.081244156\n",
      "Epoch: 0010 cost =  0.079706848\n",
      "Epoch: 0011 cost =  0.079685763\n",
      "Epoch: 0012 cost =  0.077642992\n",
      "Epoch: 0013 cost =  0.070461988\n",
      "Epoch: 0014 cost =  0.073489644\n",
      "Epoch: 0015 cost =  0.073698640\n",
      "Epoch: 0016 cost =  0.071993485\n",
      "Epoch: 0017 cost =  0.071905896\n",
      "Epoch: 0018 cost =  0.071495652\n",
      "Epoch: 0019 cost =  0.068841830\n",
      "Epoch: 0020 cost =  0.067755692\n",
      "Epoch: 0021 cost =  0.066483170\n",
      "Epoch: 0022 cost =  0.065699071\n",
      "Epoch: 0023 cost =  0.066402756\n",
      "Epoch: 0024 cost =  0.067755446\n",
      "Epoch: 0025 cost =  0.066837996\n",
      "Epoch: 0026 cost =  0.066427469\n",
      "Epoch: 0027 cost =  0.062389862\n",
      "Epoch: 0028 cost =  0.060438652\n",
      "Epoch: 0029 cost =  0.059701055\n",
      "Epoch: 0030 cost =  0.059791297\n",
      "Epoch: 0031 cost =  0.058970660\n",
      "Epoch: 0032 cost =  0.061055902\n",
      "Epoch: 0033 cost =  0.060467117\n",
      "Epoch: 0034 cost =  0.058676846\n",
      "Epoch: 0035 cost =  0.059767149\n",
      "Epoch: 0036 cost =  0.058071293\n",
      "Epoch: 0037 cost =  0.056544732\n",
      "Epoch: 0038 cost =  0.059018306\n",
      "Epoch: 0039 cost =  0.058942862\n",
      "Epoch: 0040 cost =  0.059338376\n",
      "Epoch: 0041 cost =  0.057778798\n",
      "Epoch: 0042 cost =  0.057840921\n",
      "Epoch: 0043 cost =  0.055195618\n",
      "Epoch: 0044 cost =  0.058032271\n",
      "Epoch: 0045 cost =  0.056439206\n",
      "Epoch: 0046 cost =  0.058509361\n",
      "Epoch: 0047 cost =  0.056338992\n",
      "Epoch: 0048 cost =  0.056139149\n",
      "Epoch: 0049 cost =  0.056370642\n",
      "Epoch: 0050 cost =  0.055617157\n",
      "Optimization Finished!\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    total_batch = int(mnist.train.num_examples/batch_size)\n",
    "    for epoch in range(training_epochs):\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            _,c = sess.run([optimizer, cost], feed_dict = {X:batch_xs})\n",
    "        if epoch % display_step == 0:\n",
    "            print(\"Epoch:\",\"%04d\" % (epoch+1),\n",
    "                 \"cost = \",\"{:.9f}\".format(c))\n",
    "    print(\"Optimization Finished!\")\n",
    "    \n",
    "    encoder_result = sess.run(encoder_op, feed_dict={X:mnist.test.images})\n",
    "    plt.scatter(encoder_result[:,0],encoder_result[:,1],c=mnist.test.labels)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
