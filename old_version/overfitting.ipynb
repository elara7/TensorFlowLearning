{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kenn/anaconda3/envs/tf_base/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/home/kenn/anaconda3/envs/tf_base/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "y = LabelBinarizer().fit_transform(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X , y,test_size  = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11666667\n",
      "0.77037036\n",
      "0.8333333\n",
      "0.8703704\n",
      "0.8833333\n",
      "0.90925926\n",
      "0.91851854\n",
      "0.92407405\n",
      "0.93333334\n",
      "0.9351852\n",
      "0.94074076\n",
      "0.9351852\n",
      "0.93703705\n",
      "0.9462963\n",
      "0.9444444\n",
      "0.95\n",
      "0.95\n",
      "0.9574074\n",
      "0.95555556\n",
      "0.9574074\n"
     ]
    }
   ],
   "source": [
    "def add_layer(inputs, in_size,out_size, n_layer,keep_prob, activation_function=None):\n",
    "    layer_name = 'layer_%s' % n_layer\n",
    "    # 把所有内容可视化的时候包含在layer节点内\n",
    "    with tf.name_scope(layer_name):\n",
    "        \n",
    "        with tf.name_scope(\"weights\"):\n",
    "            Weights = tf.Variable(tf.random_normal([in_size, out_size]), name=\"W\") # 权重矩阵 行=输入维度，列=输出维度（下一层输入维度）\n",
    "            # 把参数数据总结到直方图中\n",
    "            tf.summary.histogram(layer_name+\"/weights\", Weights)\n",
    "            \n",
    "        with tf.name_scope(\"biases\"):\n",
    "            biases = tf.Variable(tf.zeros([1,out_size]) + 0.1, name=\"b\")           # 偏置向量 行=1，列=输出维度\n",
    "            tf.summary.histogram(layer_name+\"/biases\", biases)\n",
    "            \n",
    "        with tf.name_scope(\"Wx_plus_b\"):\n",
    "            Wx_plus_b = tf.matmul(inputs, Weights) + biases              # 其实是xW，如果行列定义反过来，这里可以Wx，xW的比较符合数据储存直觉\n",
    "            # 加入dropout，rate由keep_prob决定\n",
    "            Wx_plus_b = tf.nn.dropout(Wx_plus_b, keep_prob)\n",
    "            \n",
    "        if activation_function is None:\n",
    "            outputs = Wx_plus_b\n",
    "        else:\n",
    "            outputs = activation_function(Wx_plus_b)\n",
    "        tf.summary.histogram(layer_name+\"/outputs\", outputs)\n",
    "        return outputs\n",
    "\n",
    "def compute_accuracy(v_xs, v_ys):\n",
    "    global prediction #先把prediction定义为全局变量\n",
    "    y_pre = sess.run(prediction, feed_dict={xs:v_xs,keep_prob_l1:1, keep_prob_l2:1}) #生成预测值（概率），10分类，所以一个样本是10列概率\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pre,1), tf.argmax(v_ys,1)) #比较概率最大值的位置和真实标签位置是否一样，一样就是true\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32)) #计算平均正确率\n",
    "    result = sess.run(accuracy, feed_dict={xs:v_xs, ys:v_ys}) #生成正确率\n",
    "    return result\n",
    "\n",
    "with tf.name_scope(\"dropout_rate_l1\"):\n",
    "    keep_prob_l1 = tf.placeholder(tf.float32)\n",
    "with tf.name_scope(\"dropout_rate_l2\"):\n",
    "    keep_prob_l2 = tf.placeholder(tf.float32)\n",
    "    \n",
    "    \n",
    "with tf.name_scope(\"inputs\"):\n",
    "    xs = tf.placeholder(tf.float32, [None,64], name = \"x_input\") # 输入数据：None不限制样本数，64=8x8,每个样本64个像素点（特征）\n",
    "    ys = tf.placeholder(tf.float32, [None,10], name = \"y_input\") # 输出数据：None不限制样本数，10个输出（10分类问题）\n",
    "\n",
    "#（隐藏层）：输入为上一层输出=64\n",
    "l1 = add_layer(xs, 64, 100, n_layer='l1',keep_prob = keep_prob_l1, activation_function=tf.nn.sigmoid)\n",
    "l2 = add_layer(l1, 100, 50, n_layer='l2',keep_prob = keep_prob_l2, activation_function=tf.nn.sigmoid)\n",
    "#（输出层）：输入为上一层输出=100，输出10\n",
    "prediction = add_layer(l2, 50, 10, n_layer='predict', keep_prob=1, activation_function=tf.nn.softmax)\n",
    "    \n",
    "with tf.name_scope(\"corss_entropy\"):\n",
    "    corss_entropy =  tf.reduce_mean(-tf.reduce_sum(ys*tf.log(prediction),reduction_indices=[1]))\n",
    "    tf.summary.scalar(\"corss_entropy\",corss_entropy)\n",
    "    \n",
    "with tf.name_scope(\"train\"):\n",
    "    train_step = tf. train.GradientDescentOptimizer(0.5).minimize(corss_entropy)\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "# 将上述可视化合并\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "# 将以上结构写入文件，分为train和test\n",
    "train_writer = tf.summary.FileWriter(\"logs/overfitting/train\",sess.graph)\n",
    "test_writer = tf.summary.FileWriter(\"logs/overfitting/test\",sess.graph)\n",
    "# 终端激活对应环境后执行 tensorboard --logdi'file:///home/kenn/tensorflow_learning/logs'\n",
    "# localhost:6006看\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "for i in range(10000):\n",
    "    #通过placeholder定义输入的话，都要用feed_dict载入数据，dropout参数也要从这里输入\n",
    "    sess.run(train_step, feed_dict = {xs:X_train, ys:y_train, keep_prob_l1:0.5, keep_prob_l2:0.3})\n",
    "    \n",
    "    if i%500 == 0:\n",
    "        print(compute_accuracy(X_test, y_test))\n",
    "        \n",
    "        #预测的时候droprate为0\n",
    "        train_result = sess.run(merged, feed_dict = {xs:X_train, ys:y_train, keep_prob_l1:1, keep_prob_l2:1})\n",
    "        test_result = sess.run(merged, feed_dict = {xs:X_test, ys:y_test, keep_prob_l1:1, keep_prob_l2:1})\n",
    "        \n",
    "        train_writer.add_summary(train_result,i)\n",
    "        test_writer.add_summary(test_result,i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
